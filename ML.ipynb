{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/textract-2019/textract_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['Contents'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = df['Contents']\nlabels = df['Label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=0.2, random_state=42, stratify = labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_word(sample):\n    to_replace = \"\"\"[,\\.!?'\"123456789]-():;\"\"\"\n    for char in to_replace:\n        sample = sample.replace(char,'')\n    return sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = []\nfor article in tqdm(X_train):\n    new_article = []\n    for word in article.split(' '):\n        new_word = clean_word(word)\n        if new_word != '' and new_word != ' ':\n            new_article.append(new_word)\n    new_train.append(new_article)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = []\nfor article in tqdm(X_test):\n    new_article = []\n    for word in article.split(' '):\n        new_word = clean_word(word)\n        if new_word != '' and new_word != ' ':\n            new_article.append(new_word)\n    new_test.append(new_article)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import random\n# for i  in range(len(new_train)):\n#     random.shuffle(new_train[i])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.models import Word2Vec\nw2v_size = 300\nw2v_model = Word2Vec(min_count=100,\n                     window=4,\n                     size=w2v_size,\n                     workers=2)\nw2v_model.build_vocab(new_train)\nw2v_model.train(new_train, total_examples=w2v_model.corpus_count, epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vectorizing train data\nX_train = new_train\nX_dev = new_test\npadding= np.zeros(w2v_size)\nX_train_vec = []\ndim = 200\nfor sample in X_train:\n    vec = []\n    k = 0\n    for word in sample:\n        if k >= dim:\n            break\n        k += 1\n        try:\n            vec.append(w2v_model.wv[word])\n        except:\n            vec.append(padding)\n    while k < dim:\n        vec.append(padding)\n        k += 1\n    X_train_vec.append(np.array(vec))\nX_train_vec = np.array(X_train_vec)\n\n# vectorizing dev data\npadding= np.zeros(w2v_size)\nX_dev_vec = []\nfor sample in X_dev:\n    vec = []\n    k = 0\n    for word in sample:\n        if k >= dim:\n            break\n        k += 1\n        try:\n            vec.append(w2v_model.wv[word])\n        except:\n            vec.append(padding)\n    while k < dim:\n        vec.append(padding)\n        k += 1\n    X_dev_vec.append(np.array(vec))\nX_dev_vec = np.array(X_dev_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_dev = X_dev_vec\nX_train = X_train_vec\ny_dev = y_test\nprint(X_train.shape)\nprint(X_dev.shape)\nprint(y_train.shape)\nprint(y_dev.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, LSTM, Bidirectional, GlobalMaxPooling1D, Conv1D, Dropout, MaxPool1D\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, CSVLogger, Callback, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(LSTM(128, return_sequences = 'True'))\n    model.add(Dropout(0.5))\n    model.add(LSTM(64))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\ndef train_model(model, X_train, y_train, X_test, y_test):\n    mcp_save = ModelCheckpoint('model.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n    model.fit(X_train, y_train,validation_data=[X_test, y_test], batch_size=32, epochs=100,  \n                        callbacks= [\n                              EarlyStopping(patience=10, monitor='val_loss', mode='min'),\n                              mcp_save,\n                              ReduceLROnPlateau(factor=.3)\n                         ])\n    model.load_weights(filepath = 'model.hdf5')\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = build_model()\ntrain_model(m,X_train, np.array(list(y_train)), X_dev, np.array(list(y_dev)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}